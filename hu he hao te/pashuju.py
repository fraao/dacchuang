# -*- codeing = utf-8 -*-ï¼ˆé˜²æ­¢ä¸­æ–‡ä¹±ç ï¼‰
# @Time : 2021/1/22 14:33ï¼ˆæ—¶é—´ï¼‰
# @Auther : IGfraAoï¼ˆç”¨æˆ·åå­—ï¼‰
# @File : 1.pyï¼ˆå½“å‰æ–‡ä»¶åï¼‰
# @Software: ï¼ˆè½¯ä»¶åç§°ï¼‰
import jieba
import bs4   #ç½‘é¡µè§£æï¼Œè·å–æ•°æ®
import re    #æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿›è¡Œæ–‡å­—åŒ¹é…
import urllib.request,urllib.error   #åˆ¶å®šurlï¼Œè·å–ç½‘é¡µæ•°æ®
import xlwt  #è¿›è¡Œexcelæ“ä½œ
import sqlite3 #è¿›è¡Œsqliteæ•°æ®åº“æ“ä½œ
from bs4 import BeautifulSoup
import pandas as pd

def main():
    baseurl = "https://www.mafengwo.cn/poi/6326821.html"
    #1.çˆ¬å–ç½‘é¡µ
    getdata(baseurl)
    #2.é¢‘åº¦åˆ†æ
    #count()

#åˆ›å»ºæ­£åˆ™è¡¨è¾¾å¼å¯¹è±¡ï¼Œè¡¨ç¤ºæ¨¡æ¿
findlink = re.compile(r'<a href="(.*?)">') #å½±ç‰‡è¶…é“¾æ¥çš„è§„åˆ™
findimgsrc = re.compile(r'<img.*src="(.*?)"',re.S) #å½±ç‰‡å›¾ç‰‡çš„è§„åˆ™ï¼Œre.Sè®©æ¢è¡Œç¬¦åŒ…å«åœ¨å­—ç¬¦ä¸­
findtitle = re.compile(r'<span class="title">(.*)</span>') #å½±ç‰‡ç‰‡åçš„è§„åˆ™
findrating = re.compile(r'<span class="rating_num" property="v:average">(.*)</span>') #å½±ç‰‡è¯„åˆ†çš„è§„åˆ™
findjudge = re.compile(r'<span>(\d*)äººè¯„ä»·</span>') #è¯„ä»·äººæ•°çš„è§„åˆ™
findinq = re.compile(r'<span class="inq">(.*)</span>') #æ¦‚å†µçš„è§„åˆ™
findbd = re.compile(r'<dd class="item-short">(.*?)<dd class="item-prac">',re.S) #å½±ç‰‡ç›¸å…³å†…å®¹çš„è§„åˆ™


#çˆ¬å–ç½‘é¡µ
def getdata(baseurl):
    for i in range(1,445):#è°ƒç”¨è·å–é¡µé¢ä¿¡æ¯çš„å‡½æ•°10æ¬¡
        url = baseurl + str(i) + str(".html")
        html= askURl(url)    #ä¿å­˜è·å–åˆ°çš„ç½‘é¡µæºç 


        # 2.é€ä¸€è§£ææ•°æ®
        soup = BeautifulSoup(html,"html.parser")
        for item in soup.find_all('div',class_="iteminner"): #æŸ¥æ‰¾ç¬¦åˆè¦æ±‚çš„å­—ç¬¦ä¸²å½¢æˆåˆ—è¡¨
            data = []  #ä¿å­˜ä¸€éƒ¨ç”µå½±çš„æ‰€æœ‰ä¿¡æ¯
            item=str(item)

            link = re.findall(findbd,item)[0]  #reåº“ç”¨æ¥é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æŒ‡å®šçš„å­—ç¬¦ä¸²
            link = link.replace("......</dd>","")
            link = link.replace("\n", "") #æ¸…é™¤æ¢è¡Œç¬¦
            link = link.replace("\u3000","")
            link = link.replace("ï¼Œ", "")
            link = link.replace("ã€‚", "")
            link = link.replace("ï¼", "")
            link = link.replace("+", "")
            link = link.replace("â€˜", "")
            link = link.replace("ï¼š", "")
            link = link.replace("â€œ", "")
            link = link.replace("ï¼Ÿ", "")
            link = link.replace("Â·", "")
            link = link.replace("-", "")
            link = link.replace("~", "")
            link = link.replace("ã€Š", "")
            link = link.replace("ã€‹", "")
            link = link.replace("ã€", "")
            link = link.replace("â€¦", "")
            link = link.replace("[", "")
            link = link.replace("]", "")
            link = link.replace("ğŸ”º", "")
            link = link.replace("ï½œ", "")
            link = link.replace("------", "")
            link = link.replace("â˜…", "")
            link = link.replace(".....", "")
            link = link.replace("=", "")
            f = open("æ­¦æ±‰æ—…æ¸¸è¯„ä»·.txt", 'a', encoding='utf-8')  # å‚¨å­˜åœ°å€
            f.write(str(link))
        print(i)  # è·å–å½±ç‰‡è¶…é“¾æ¥



#å¾—åˆ°ä¸€ä¸ªæŒ‡å®šä¸€ä¸ªURLçš„ç½‘é¡µå†…å®¹
def askURl(url):
    #ç”¨æˆ·ä»£ç†è¡¨ç¤ºå‘Šè¯‰è±†ç“£æœåŠ¡å™¨ï¼Œæˆ‘ä»¬æ˜¯ä»€ä¹ˆç±»å‹çš„æµè§ˆå™¨ï¼ˆæœ¬è´¨æ˜¯å‘Šè¯‰æµè§ˆå™¨ï¼Œæˆ‘ä»¬å¯ä»¥æ¥å—ä»€ä¹ˆæ°´å¹³çš„æ–‡ä»¶å†…å®¹ï¼‰
    #æ¨¡æ‹Ÿæµè§ˆå™¨å¤´éƒ¨ä¿¡æ¯ï¼Œå‘è±†ç“£æœåŠ¡å™¨å‘é€æ¶ˆæ¯
    head = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36 Edg/87.0.664.75"}
    request =urllib.request.Request(url,headers=head)
    html =""
    try:
        response=urllib.request.urlopen(request)
        html=response.read().decode("utf-8")
        # print(html)
    except urllib.error.URLError as e:
        if hasattr(e,"code"):
            print(e.code)
        if hasattr((e,"reason")):
            print(e.reason)
    print(html)
    return html

def count():

    content =open("æ­¦æ±‰æ—…æ¸¸è¯„ä»·.txt",'r',encoding='utf-8').read()
    seg_list = jieba.cut(content)  # jiebaåˆ†è¯ï¼Œé»˜è®¤æ˜¯ç²¾ç¡®æ¨¡å¼
    liststr = "/".join(seg_list)
    count_dict = {}
    for ite in liststr.split('/'):
        if ite in count_dict:
            count_dict[ite] += 1
        else:
            count_dict[ite] = 1  # Counter({â€˜Dogâ€™: 3, 42: 2, â€˜Catâ€™: 2, â€˜Mouseâ€™: 1}
    q = open(r'åˆ†è¯é¢‘æ•°.txt','w',encoding='utf-8')  # å‚¨å­˜åœ°å€
    q.write(str(count_dict))
    p = pd.DataFrame.from_dict(dict(count_dict), orient='index')#ä¿å­˜è¯é¢‘æ•°æ®åˆ°csv
    p.to_csv('æœ€ç»ˆè¯é¢‘è¡¨.csv', encoding='utf-8')

if __name__ =="__main__":#å½“ç¨‹åºæ‰§è¡Œæ—¶
#     è°ƒç”¨å‡½æ•°
     main()